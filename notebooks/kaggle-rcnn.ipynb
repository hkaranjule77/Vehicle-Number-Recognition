{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# RCNN"],"metadata":{}},{"cell_type":"markdown","source":["**Reference:** https://www.youtube.com/watch?v=IcLEJB2pY2Y&t=2055s"],"metadata":{}},{"cell_type":"code","source":["%config Completer.use_jedi = False    # for autocompletion"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import albumentations\n","import glob\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from sklearn import preprocessing\n","from sklearn import model_selection\n","from sklearn import metrics\n","\n","from PIL import Image\n","from PIL import ImageFile\n","from pprint import pprint\n","from tqdm import tqdm"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# constants: configurations\n","if os.path.exists('gen-plate-dataset'):\n","    DATA_DIR = 'gen-plate-dataset'\n","else:\n","    DATA_DIR = os.path.join('..', 'datasets', 'gen-plate-dataset')\n","BATCH_SIZE = 1\n","IMAGE_WIDTH = 230\n","IMAGE_HEIGHT = 50\n","NUM_WORKERS = 12\n","DEVICE = 'cuda'  # cpu / cuda\n","LR = 1e-4"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if os.sys.platform=='linux' and os.path.exists('../input/unspacednumberplate/unspaced-plate-dataset'):\n","    DATA_DIR = '../input/unspacednumberplate/unspaced-plate-dataset'"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATA_DIR"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save Data"],"metadata":{}},{"cell_type":"code","source":["MODEL_DIR = os.path.join('..','models')\n","\n","try:\n","    os.mkdir(TRAIN_DIR)\n","except FileExistsError:\n","    pass"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TRAINER_DIR = os.path.join(MODEL_DIR,'harshad')    # change this\n","\n","try:\n","    os.mkdir(TRAINER_DIR)\n","except FileExistsError:\n","    pass"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# change this for every training\n","# or it will overwrite your previous data\n","\n","VER_FILE = os.path.join('text_recognition-ver-28.0.pth')\n","\n","comment = '1) captcha architecture 2) unspaced 957'"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save state\n","def save_model():\n","    torch.save(\n","        {'lr': LR,\n","        'train_epoch': epoch_count,\n","        'model': PlateRecognizer(num_chars=len(lbl_enc.classes_)),\n","        'model_state_dict': model.state_dict(),\n","        'classes': lbl_enc.classes_,\n","        'optimizer_name': optimizer_name,\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'scheduler_state_dict': schedular.state_dict(),\n","        'scheduler_name': schedular_name,\n","        'loss': loss,\n","        'accuracy': accuracy,\n","        'comment':comment},\n","        VER_FILE\n","    )"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{}},{"cell_type":"code","source":["# dataset creations\n","\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","\n","class ClassificationDataset:\n","    def __init__(self, img_paths, targets, resize=None):\n","        self.img_paths = img_paths\n","        self.targets = targets\n","        self.resize = resize\n","        self.aug = albumentations.Compose(\n","            [albumentations.Normalize(always_apply=True)])\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, item_index):\n","        img = Image.open(self.img_paths[item_index])\n","        targets = self.targets[item_index]\n","\n","        if self.resize is not None:\n","            img = img.resize((self.resize[1], self.resize[0]),\n","                             resample=Image.BILINEAR)\n","\n","        img = np.array(img)\n","        augmented = self.aug(image = img)\n","        img = augmented['image']\n","        img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","        return {\n","            'imgs': torch.tensor(img, dtype=torch.float),\n","            'targets': torch.tensor(targets, dtype=torch.long)\n","        }"],"metadata":{"code_folding":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Engine"],"metadata":{}},{"cell_type":"code","source":["# engine\n","\n","\n","def train_fn(model, data_loader, optimizer):\n","    model.train()\n","    fin_loss = 0\n","    tk = tqdm(data_loader, total=len(data_loader))\n","    for data in tk:\n","        for k, v in data.items():\n","            data[k] = v.to(DEVICE)\n","        optimizer.zero_grad()\n","        _, loss = model(**data)\n","        loss.backward()\n","        optimizer.step()\n","        fin_loss += loss.item()\n","\n","    return fin_loss / len(data_loader)\n","\n","\n","def eval_fn(model, data_loader, optimizer):\n","    model.eval()\n","    fin_loss = 0\n","    fin_preds = []\n","    with torch.no_grad():\n","        tk = tqdm(data_loader, total=len(data_loader))\n","        for data in tk:\n","            for k, v in data.items():\n","                data[k] = v.to(DEVICE)\n","            batch_preds, loss = model(**data)\n","\n","            fin_loss += loss.item()\n","            fin_preds.append(batch_preds)\n","\n","        return fin_preds, fin_loss / len(data_loader)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{}},{"cell_type":"code","source":["# model\n","\n","class PlateRecognizer(nn.Module):\n","    def __init__(self, num_chars):\n","        super(PlateRecognizer, self).__init__()\n","        self.conv1 = nn.Conv2d(3,128, kernel_size=(3, 6), padding=(1, 1))\n","        self.max_pool_1 = nn.MaxPool2d(kernel_size=(2, 2))\n","        self.conv2 = nn.Conv2d(128, 64, kernel_size=(3, 6), padding=(1, 1))\n","        self.max_pool_2 = nn.MaxPool2d(kernel_size=(2, 2))\n","\n","        self.linear = nn.Linear(768, 64)\n","        self.drop = nn.Dropout(0.2)  # doesn't change size\n","\n","        self.gru = nn.GRU(64,\n","                          32,\n","                          bidirectional = True,\n","                          num_layers=2,\n","                          dropout=0.25,\n","                          batch_first=True\n","                         )\n","        self.output = nn.Linear(64, num_chars + 1)\n","\n","    def forward(self, imgs, targets=None):\n","        bs, c, w, h = imgs.size()\n","        # print(bs, c, w, h)    # for debugging\n","        x = F.relu(self.conv1(imgs))\n","        # print('Conv1', x.size())\n","        x = self.max_pool_1(x)\n","        # print('MaxPool', x.size())\n","        x = F.relu(self.conv2(x))\n","        # print('Conv2', x.size())\n","        x = self.max_pool_2(x)  # 1, 64, 12, 57\n","        # print('MaxPool', x.size())\n","\n","        # to brind width first but in our case it's properly arranged\n","        x = x.permute(0, 3, 1, 2)  # 1, 57, 64, 12\n","        # print('Permute', x.size())\n","        x = x.view(bs, x.size(1), -1)\n","        # print('View', x.size())\n","\n","        x = self.linear(x)\n","        x = self.drop(x)\n","        # print('Linear', x.size())\n","\n","        x, _ = self.gru(x)\n","        # print('Recurrent', x.size())\n","\n","        x = self.output(x)\n","        # print('output', x.size())\n","\n","        x = x.permute(1, 0, 2)\n","        if targets is not None:\n","            # CTC\n","            log_probs = F.log_softmax(x, 2)\n","            input_lengths = torch.full(size=(bs, ),\n","                                       fill_value=log_probs.size(0),\n","                                       dtype=torch.int32)\n","            # print('input lengths', input_lengths)\n","            target_lengths = torch.full(size=(bs, ),\n","                                        fill_value=targets.size(1),\n","                                        dtype=torch.int32)\n","            # print('target lengths', target_lengths)\n","            loss = nn.CTCLoss(blank=0)(log_probs, targets,\n","                                       input_lengths, target_lengths)\n","            return x, loss\n","\n","        return x, None"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for debugging model\n","\n","cm = PlateRecognizer(19)\n","img = torch.rand(5, 3, IMAGE_HEIGHT, IMAGE_WIDTH)\n","targets = torch.randint(1, 6, (5, 5))\n","x, loss = cm(img, targets)\n","\n","del (cm)"],"metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{}},{"cell_type":"code","source":["# generate img & target list\n","\n","\n","def get_img_label():\n","    '''Returns tuple of img filename list and target_label list.'''\n","    img_files = glob.glob(os.path.join(DATA_DIR, '*.jpg'))\n","    img_files.extend(glob.glob(os.path.join(DATA_DIR, '*.png')))\n","    if os.sys.platform == 'win32':\n","        separator = '\\\\'\n","    else:\n","        separator = '/'\n","    targets_orig = [x.split(separator)[-1][:-4] for x in img_files]\n","    return img_files, targets_orig"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target preprocessing\n","\n","\n","def get_target_list(target_orig):\n","    targets = [[c for c in x] for x in targets_orig]\n","    targets_flat = [c for clist in targets for c in clist]\n","    return targets, targets_flat"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target encoding\n","\n","\n","def encode_labels(targets, targets_flat):\n","    lbl_enc = preprocessing.LabelEncoder()\n","    lbl_enc.fit(targets_flat)\n","    targets_enc = [lbl_enc.transform(x) for x in targets]\n","    # 1 is added to shift characters as 0 index will be reserved for null Value\n","    # null is not whitespace character\n","    targets_enc = np.array(targets_enc) + 1\n","    return lbl_enc, targets_enc"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# decodes labels\n","\n","\n","def decode_predictions(preds, encoder, collapse_repeated=True):\n","    ''' Decodes CTC String to normal string'''\n","    preds = preds.permute(1, 0, 2)\n","    preds = torch.softmax(preds, 2)\n","    preds = torch.argmax(preds, 2)\n","    preds = preds.detach().cpu().numpy(\n","    )  # change cpu to cuda if training on gpu\n","    cap_preds = []\n","    for j in range(preds.shape[0]):\n","        temp = ''\n","        prev_char = None\n","        for k in preds[j]:\n","            k = k - 1\n","            # k = -1 mean a empty value\n","            if k == -1: # or (collapse_repeated and k == prev_char):\n","                temp += '`'\n","            else:\n","                # print(encoder.inverse_transform([k]), k)\n","                temp += encoder.inverse_transform([k])[0]\n","            prev_char = k\n","        tp = \"\" + temp\n","        # print(preds[j], targets[j], tp)\n","        cap_preds.append(tp)\n","    return cap_preds"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checks if all characters of targets are in predictions\n","\n","\n","def char_accuracy(preds, targets):\n","    sum_accuracy = 0\n","    total_preds = 0\n","    for index in range(len(preds)):\n","        correct_char = 0\n","        for char in preds[index]:\n","            if char in targets[index]:\n","                correct_char += 1\n","        accuracy = correct_char / len(preds[index])\n","        sum_accuracy += accuracy\n","        total_preds += 1\n","    return sum_accuracy / total_preds"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checks if all predictions are same as labels\n","\n","\n","def label_accuracy(preds, targets):\n","    correct_labels = 0\n","    for index in range(len(preds)):\n","        if preds[index] == targets[index]:\n","            correct_labels += 1\n","    return correct_labels / len(preds)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data preprocessing & encoding\n","\n","img_files, targets_orig = get_img_label()\n","\n","targets, targets_flat = get_target_list(targets_orig)\n","lbl_enc, targets_enc = encode_labels(targets, targets_flat)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data splitting\n","\n","(train_imgs, test_imgs, train_targets, test_targets, train_orig_targets,\n"," test_orig_targets) = model_selection.train_test_split(img_files,\n","                                                       targets_enc,\n","                                                       targets_orig,\n","                                                       test_size=0.1,\n","                                                       random_state=42)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train dataset & loader\n","\n","train_dataset = ClassificationDataset(\n","                    img_paths=train_imgs, \n","                    targets=train_targets,\n","                    resize=(IMAGE_HEIGHT, IMAGE_WIDTH)\n","                )\n","\n","train_loader = torch.utils.data.DataLoader(\n","                    train_dataset,\n","                    batch_size = BATCH_SIZE,\n","                    num_workers = NUM_WORKERS,\n","                    shuffle = True\n","                )\n","\n","# for debugging\n","\n","# npimg = train_dataset[0]['imgs'].numpy()\n","# plt.imshow(np.transpose(npimg, (1, 2, 0)))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_dataset & loader\n","\n","test_dataset = ClassificationDataset(\n","                    img_paths = test_imgs,\n","                    targets = test_targets,\n","                    resize = (IMAGE_HEIGHT, IMAGE_WIDTH)\n","                )\n","test_loader = torch.utils.data.DataLoader(\n","                test_dataset,\n","                batch_size = BATCH_SIZE,\n","                num_workers = NUM_WORKERS,\n","                shuffle = False\n","            )"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Visualization"],"metadata":{}},{"cell_type":"code","source":["lbl_enc.classes_"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_dataset), len(test_dataset)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train data visualization\n","\n","img = train_dataset[11]['imgs']\n","lbl_int = train_dataset[0]['targets'] - 1    # 1 is subtracted as it was added during encoding process\n","label = lbl_enc.inverse_transform(lbl_int)\n","print(img.shape)\n","plt.imshow(img.permute(1, 2, 0))\n","'Image shape: ', img.shape, label"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test data visualiztion\n","\n","img = test_dataset[0]['imgs']\n","lbl_int = test_dataset[0]['targets'] - 1 # \n","label = lbl_enc.inverse_transform(lbl_int)\n","plt.imshow(img.permute(1, 2, 0))\n","label, img.shape"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model, optimizer & schedular\n","\n","model = PlateRecognizer(num_chars=len(lbl_enc.classes_))\n","model.to(DEVICE)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","optimizer_name = 'Adam'\n","schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, factor=0.8, patience=4, verbose=True\n",")\n","schedular_name = 'ReduceLROnPlateau'\n","\n"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# actual training\n","\n","def run_training(model, train_loader, test_loader, optimizer, schedular, lbl_enc):\n","    global epoch_count\n","    global max_char_acc\n","    global max_label_acc\n","    for epoch in range(epoch_count, EPOCHS):\n","        train_loss = train_fn(model, train_loader, optimizer)\n","        valid_preds, valid_loss = eval_fn(model, test_loader, optimizer)\n","        \n","        valid_plate_preds = []\n","        for vp in valid_preds:\n","            current_preds = decode_predictions(vp, lbl_enc, False)\n","            valid_plate_preds.extend(current_preds)\n","            \n","        combined = list(zip(test_orig_targets, valid_plate_preds))\n","            \n","        char_acc = char_accuracy(test_orig_targets, valid_plate_preds)\n","        label_acc = label_accuracy(test_orig_targets, valid_plate_preds)\n","            \n","        # calculate accuracy of model and log it   \n","        pprint(combined[:10])\n","        print(f\"Epoch:{epoch}, train_loss:{train_loss}, valid_loss={valid_loss}\")\n","        print(f\"char_accuracy:{char_acc}, label_accuracy:{label_acc}\")\n","        \n","        loss['train'].append(train_loss)\n","        loss['valid'].append(valid_loss)\n","        accuracy['character'].append(char_acc)\n","        accuracy['label'].append(label_acc)\n","        \n","        epoch_count += 1\n","        schedular.step(valid_loss)\n","        \n","        if max_char_acc < char_acc or max_label_acc < label_acc:\n","            save_model()\n","            max_char_acc = char_acc\n","            max_label_acc = label_acc\n","            print('Model saved')\n","        \n"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Resume Training\n","Execute following cells only if you want to resume previously trained model."],"metadata":{}},{"cell_type":"code","source":["# copy & paste files path of weights.pth & optimizer.pth\n","\n","STATE_PATH = './text_recognition-ver-27.0.pth'    # text-recognition-ver-X.X.pth"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.device('cpu')\n","checkpoint = torch.load(STATE_PATH, map_location=torch.device(DEVICE))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint['accuracy']['character'][-1]    # last accuryacy"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint['loss']['train'][-1], checkpoint['loss']['valid'][-1]    # last vloss"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loads model and optimzer\n","LR = checkpoint['lr']\n","model = checkpoint['model']\n","epoch_count = checkpoint['train_epoch']\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.to('cpu')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if checkpoint['optimizer_name'] == 'Adam':\n","    optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    print('optimizer is loaded.')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if checkpoint['scheduler_name'] == 'ReduceLROnPlateau':\n","    schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, factor=0.8, patience=5, verbose=True\n","    )\n","    schedular.load_state_dict(checkpoint['scheduler_state_dict'])\n","    print('scheduler is loaded.')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = checkpoint['loss']\n","accuracy = checkpoint['accuracy']\n","'comment: '+ checkpoint['comment']"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss['valid'][-1], accuracy['character'][-1], len(loss['valid'])"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('LR: ', LR,'\\nTrained_epoch_count: ', epoch_count, '\\nEPOCHS: ', EPOCHS)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Change **EPOCH** such that **EPOCH > epoch_count**"],"metadata":{}},{"cell_type":"code","source":["plt.title('LOSS: Train vs Valid')\n","plt.plot(loss['train'])\n","plt.plot(loss['valid'])\n","plt.legend(['train', 'valid'])\n","plt.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Accuracy: Character vs Label')\n","plt.plot(accuracy['character'])\n","plt.plot(accuracy['label'])\n","plt.legend(['character', 'label'])\n","plt.show()"],"metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Start Training "],"metadata":{}},{"cell_type":"code","source":["# one-time initialization parameters\n","loss = {'train': [], 'valid': []}\n","accuracy = {'character': [], 'label': []}\n","epoch_count = 0\n","max_char_acc = 0\n","max_label_acc = 0"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 100"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["run_training(model, train_loader, test_loader, optimizer, schedular, lbl_enc);"],"metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('LOSS: Train vs Valid')\n","plt.plot(loss['train'])\n","plt.plot(loss['valid'])\n","plt.legend(['train', 'valid'])\n","plt.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Accuracy: Character vs Label')\n","plt.plot(accuracy['character'])\n","plt.plot(accuracy['label'])\n","plt.legend(['character', 'label'])\n","plt.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# jovian commit"],"metadata":{}},{"cell_type":"code","source":["!pip install jovian"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import jovian"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jovian.commit(project=\"text-recognition\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{},"execution_count":null,"outputs":[]}]}